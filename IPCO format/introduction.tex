\section{Introduction}
Mixed-integer linear programming (MILP), the optimization of a linear objective function subject to linear and integrality constraints, is a classic NP-hard problem \cite{GJ79}. In fact it is NP-hard in general to determine if there is a feasible solution to an MILP problem \cite{GJ79}. However, intelligent branch-and-bound strategies allow commercial and open-source MIP solvers to give exact solutions (or near-optimal with provable bound) to many specific instances of NP-hard combinatorial optimization problems. Modeling combinatorial optimization problems with MILPs also started the very popular area of LP-based approximation algorithms. 

Consider the set of points described by a set 
\begin{equation}
S(A,G,b)= \{(x,y)\in \bbbz^{n}\times \bbbr^p\;:\; Ax+Gy\geq b\}  \label{S}
\end{equation}
and the  linear relaxation of set $S(A,G,b)$,
\begin{equation}
P(A,G,b) = \{(x,y)\in \bbbr^{n+ p}\;:\; Ax+Gy\geq b\}. \label{P}
\end{equation}

To make the notation simpler we use $I=(A,G,b)$, i.e. an instance of the formulation. Then we use $S(I)$ and $P(I)$ to denote $S(A,G,b)$ and $P(A,G,b)$, respectively. Notice that $\min \;\{cx:\; (x,y) \in S(I)\}$ is in fact an MILP problem and $\min \;\{cx:\;(x,y)\in P(I) \}$ is lower bound provided from the LP relaxation. Let $z_{IP}(I,c)$ and $z_{LP}(I,c)$ be the optimal solution to these problems, respectively.


Many researchers (see \cite{vazirani,sw}) have developed polynomial time algorithms that find solutions for special classes of MILPs whose cost are provably smaller than $C\cdot z_{LP}(I,c)$ for some $C$ which can be a constant number or dependent on some parameter of the MILP, e.g. $O(\log(n))$. However, for many combinatorial optimization problems there is a limit to such techniques. Let $g_I= \max_{c\geq 0}\frac{z_{IP}(I,c)}{z_{LP}(I,c)}$. Parameter $g_I$ depends on set $S(I)$ and the linear constraints in (\ref{S}) and is known as the \textit{integrality gap} of the formulation for instance $I$. It is easy to see, that we cannot hope to find solutions for the MILP with objective values better than $g_I\cdot z_{LP}(I,c)$. More generally we can define the integrality gap for a class of instances $\mathcal{I}$. In this case, the integrality gap for problem $\mathcal{I}$ is
\begin{equation}
g_\mathcal{I} = \max_{c\geq 0 , I\in\mathcal{I}}\frac{z_{IP}(I,c)}{z_{LP}(I,c)}
\end{equation}


For example, in the problem of finding a minimum weight 2-edge-connected multigraph, the gap of the the natural formulation, constraining every cut to be crossed at least twice, is at most $\frac{3}{2}$ \cite{Wolsey1980} and at least $\frac{6}{5}$ \cite{carr-ravi}. Therefore, we cannot hope to obtain an LP-based $(\frac{6}{5}-\epsilon)$-approximation algorithm for this problem using this LP relaxation. If we have $g_I=1$, $P(I)=\conv(S(I))$ and $P(I)$ is an \textit{integral} polyhedron. There are many interesting examples of such formulations such as spanning tree polytope and the perfect matching polytope \cite{schrijver}. For such problems we know how to write a vector $x\in P(I)$ as convex combination of points in $S(I)$ in polynomial time \cite{cons-cara}.

\begin{proposition}\label{cara}
	If $g_I=1$, then for $(x,y)\in P(I)$, there exists $\theta \in [0,1]^k$, where $\sum_{i=1}^{k}\theta_i =1$ and $(\tilde{x}^i,\tilde{y}^i)\in S(I)$ for $i=1,\ldots,k$ such that $\sum_{i=1}^{k}\theta_i \tilde{x}^i\leq x$. Moreover, we can find such a convex combination in polynomial time.
\end{proposition}

Now assume $1<g(I)<\infty$. Denote by $\dom(P(I))$ be the set of points $(x',y')$ such that there exists a point $(x,y)\in P$ with $x'\geq x$, also known as the dominant of $P(I)$. Notice that for covering problems the dominant of a polyhedron is essentially the same as its dominant, but for problems that are not covering, the two might be different. We show later, for $I$ with $g(I)<\infty$, the notation of dominant is in fact useful.

A analogous result to Proposition \ref{cara} is the following theorem due to Carr and Vempala \cite{CV}, which is a generalization of Goemans proof for blocking polyhedra \cite{goemans}. 

\begin{theorem}[Carr, Vempala \cite{CV}] \label{CV}
	Let $(x,y)\in P(I)$, there exists $\theta \in [0,1]^k$, where $\sum_{i=1}^{k}\theta_i =1$ and $(\tilde{x}^i,\tilde{y}^i)\in \dom(S(I))$ for $i=1,\ldots,k$ such that $\sum_{i=1}^{k}\theta_i \tilde{x}^i\leq Cx$ if and only if $g_I \leq C$.
\end{theorem}

In contrast to Proposition \ref{cara} which implies exact algorithms for problems with a gap of 1, Theorem \ref{CV} does not imply an approximation algorithm, since it does not suggest how to find such a convex combination in polynomial time. This points to an interesting open question. 

\begin{question}\label{question1}
	Assume reasonable complexity assumptions (such as UGC or $\textrm{P}\neq \textrm{NP}$). Given instance $I$ with $1<g_I<\infty$ and $(x,y)\in P(I)$, can we find $\theta \in [0,1]^k$, where $\sum_{i=1}^{k}\theta_i =1$ and $(\tilde{x}^i,\tilde{y}^i)\in \dom(\conv(S(I)))$ for $i=1,\ldots,k$ such that $\sum_{i=1}^{k}\theta_i \tilde{x}^i\leq g_Ix$ in polynomial time?
\end{question}

This seems to be a very hard question. A more specific question is of more interest.

\begin{question}\label{question2}
	Assume reasonable complexity assumptions, a specific problem $\mathcal{I}$ with  $1<g_{\mathcal{I}}<\infty$, and $(x,y)\in P(I)$ for some $I\in \mathcal{I}$, can we find $\theta \in [0,1]^k$, where $\sum_{i=1}^{k}\theta_i =1$ and $(\tilde{x}^i,\tilde{y}^i)\in S(I)$ for $i=1,\ldots,k$ such that $\sum_{i=1}^{k}\theta_i \tilde{x}^i\leq g_{\mathcal{I}}x$ in polynomial time?
\end{question}
Although Question \ref{question2} is wide open, for some problems there are polynomial time algorithms closing the gap. For example, for generalized Steiner forest problem \cite{jain} gave an LP-based 2-approximation algorithm. The gap for this problem is also lower bounded by 2. Same holds for the set covering problem \cite{randomizedrounding}. In fact, for set cover the approximation algorithm achieving the same factor as the integrality gap lower bound, is a \textit{randomized rounding} algorithm. Raghavan and Thompson \cite{randomizedrounding} showed that this technique achieves provably good approximation for many combinatorial optimization problems.  

If we relax Question \ref{question1} (resp. Question \ref{question2}), but multiplying $g(I)$ (resp. $g(\mathcal{I})$) by a factor $C$, they are still very interesting, since they will provide upper bounds on the integraltiy gap the instance (resp. the problem). The results in this paper serve this purpose.

We give a general approximation framework for solving $\{0,1\}$-MILPs.  Consider the set of point described by a set 
\begin{equation}
S(I)= \{(x,y)\in \bbbr^{n\times p}\;:\; Ax+Gy\geq b,\; x\in \{0,1\}\},  \label{S'} 
\end{equation}
and a linear relaxation of set $S$
\begin{equation}
P(I) = \{(x,y)\in \bbbr^{n\times p}\;:\; Ax+Gy\geq b,\; 0 \leq x\leq 1\}. \label{P'}
\end{equation}
For a vector $x\in \bbbr^n$ such that $(x,y)\in P(I)$ for some $y\in \bbbr^p$, let $\spp(x)= \{i \in \{1,\ldots,n\}: x_i \neq 0\}$. 


The \textit{Fractional Decomposition Tree} algorithm (henceforth FDT) is a polynomial time algorithm that given a point $x\in P(I)$ produces a convex combination of feasible point in $S(I)$ that are dominates by a ``factor" of $x$. If this factor is $g_I$, it would settle Question \ref{question2}, however we can only guarantee a factor of $g_I^{|\spp(x)|}$. FDT relies on iteratively solving linear programs that are about the same size as the description of $P(I)$.

\begin{restatable}{theorem}{binaryFDT}
	\label{binaryFDT}
	Assume $1\leq g_I 	<\infty$. 	
	The Fractional Decomposition Tree (FDT) algorithm , given $(x^*,y^*)\in P(I)$, produces in polynomial time $\lambda\in [0,1]^k$ and $(z^1,w^1),\ldots,(z^k,w^k) \in S(I)$ such that $k\leq |\spp(x^*)|$, $\sum_{i=1}^{k}\lambda_i z^i\leq Cx^*$, and $\sum_{i=1}^{k}\lambda_i = 1$. Moreover, $C\leq g_I^{|\spp(x^*)|}$.
\end{restatable}

Notice, that the FDT algorithm needs to find feasible solutions to any MILP with finite gap. This can be of independent interest.
\begin{restatable}{theorem}{DomToIP}
	\label{domtoIP}
	Assume $1\leq g_I < \infty$. The DomToIP algorithm finds $(\hat{x},\hat{y})\in S(I)$ in polynomial time.
\end{restatable}


Note that for general $I$ it is NP-hard to even decide if $S(I)$ is empty or not. There are a number of heuristics for this purpose, such as the feasibility pump heuristic \cite{fp1,fp2}. These heuristics are often very effective and fast in practice, however, they can sometimes fail in finding a feasible solution. In addition these algorithms do not provide any bounds on the quality of the solution they find. 


One can trivially extend the FDT algorithm for binary MILPs into covering $\{0,1,2\}$-MILPs by losing a factor $2^{|\spp(x)|}$. In order to eradicate this factor, we need to treat the coordinate $i$ with $x_i=1$ differently. For  the 2-edge-connected subgraph problem we show how this can be done. In this problem we want to find the minimum weight 2-edge-connected subgraph (which can multiple copies of each edge) in a graph $G=(V,E)$ with respect to weights $c\in \bbbr^E_{\geq 0}$. For this problem the natural linear programming relaxation is
\begin{equation}\label{2ECpol}
\EC(G)= \{x\in \bbbr_{\geq 0}^{E}\;:\; x(\delta(S))\geq 2 \text{ for $\emptyset \subset S\subset V$})\}.\end{equation}
We prove the following theorem.

\begin{restatable}{theorem}{FDTEC}
	\label{FDT2EC}
	Let $G=(V,E)$ and $x$ be an extreme point of  $\EC(G)$. The FDT algorithm for 2EC produces $\lambda\in [0,1]^k$ and 2-edge-connected multigraphs $F_1,\ldots,F_k$ such that $k\leq 2|V|-1$, $\sum_{i=1}^{k}\lambda_i \chi^{F_i}\leq Cx^*$, and $\sum_{i=1}^{k}\lambda_i = 1$. Moreover, $C\leq g({\EC})^{k}$, where $g({\EC})$ is the integrality gap of the 2-edge-connected multigraph problem with respect to formulation in (\ref{2ECpol}) 
\end{restatable}


Although the bound guaranteed in both Theorems \ref{binaryFDT} and \ref{FDT2EC} are very large for large problems, we show that in practice, the algorithm works very well providing approximation ratios that are far better than the theoretical bound in the theorem statements. We examine FDT for binary MILPs for problems such as the tree augmentation problem (TAP) and we apply FDT for 2EC on some interesting and ``hard to decompose" points in the linear relaxation. Our computational results show that the FDT algorithm is a good tool to evaluate the integrality gap of integer programming formulations. 

Evaluating the integrality gap for instances of interesting problems such as TSP or $\EC$ have been done by others as well. For instance, Benoit and Boyd \cite{TSPcompute} used a quadratic programming model to show that the integrality gap for TSP is at most $\frac{20}{17}$ for instances with at most 10 vertices. Also,  Alexander et. al \cite{abe} used the same ideas to provide an upper bound of $\frac{7}{6}$ for $\EC$ on instances with at most 10 vertices. For $\EC$ we can show that the integrality gap of $\EC$ is at most $\frac{6}{5}$ for fundamental vertices with 12 vertices. In fact, since FDT can be applied to different problem, we can use it to evaluate the integrality gap of other well-known problem. For example, for TAP, we create random fractional extreme points and round them using FDT. For the instances that we create the blow-up factor is always below $\frac{3}{2}$ providing an upper bound for such instances.


\iffalse{
Finally we give a stronger characterization of integrality gap than that in Theorem \ref{CV} for bounded covering problems. For this purpose assume $P= \{x\in \bbbr^n_{\geq 0}: Ax\geq b\textbf{1}, x \leq b\textbf{1}\}$, $S= P\cap \bbbz^n$, and $g= \max_{c\geq 0} \frac{\min_{x\in S}cx}{\min_{x\in P}cx}$. Examples of such problems include the 2-edge-connected multigraph problem, the tree augmentation problem, and many others.


\begin{restatable}{theorem}{tightcuts}
	\label{tightcuts}
	Let $x\in P$, there exists $\theta\in [0,1]^k$, where $\sum_{i=1}^{k}\theta_i = 1$ and $\tilde{x}^i \in S$ for $i=1,\ldots,k$ such that \begin{itemize}
		\item for $\ell\in \{1,\ldots,n\}$, if $x_\ell =0$, then $\tilde{x}^i_\ell=0$ for $i =1,\ldots,k$, i.e. $\tilde{x}^i$ is in the support of $x$,
		\item we have $Cb = C\cdot A_j x \geq A_j (\sum_{i=1}^{k}\theta_i\tilde{x}^i)$, for $j$ such that $A_j x =b$,  
	\end{itemize}
	if and only if $C\geq g$.
\end{restatable}



This means in order to prove an upper bound on the integrality gap of a covering problem, we need to show there is a convex combination of integer feasible points that is ``cheap'' on all tight cuts. Notice that Theorem \ref{CV} requires the certificate convex combination to be ``cheap" on every single variable.
\subsection{Notations}
For vectors $x,y\in \bbbr_{n}$ we say $x$ dominates $y$ if $x_i\geq y_i$ for $i= 1,\ldots,n$. For $m\times n$ matrix $A$, let $A_j$ be the $j$-th row of $A$ and $A^j$ be the $j$-th column of $A$. Let $\textbf{1}$ be the vector of all ones of a suitable dimension. For a set $S$ of vectors in $\bbbr_{n}$, $\conv(S)$ is the convex hull of all the points in $S$.
}\fi
