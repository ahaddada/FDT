% TODO: deal with the issue of no credit after branching up for packing:
% y_0 + y_1 \le x becomes y_0 + lambda_1 \le x
\documentclass[11pt]{article}
\date {}
\textwidth=6.5in
\textheight=9.0in
\oddsidemargin=0.0in
\topmargin=0.0in
\headheight=0.0in
\headsep=0.0in

\usepackage{ifthen}
\usepackage{boxedminipage}
\usepackage{alltt}
%\usepackage{latexsym}
%\usepackage{epsfig}
%\usepackage{graphicx}
\usepackage{color}
\usepackage{url}

% LP environments
% NEEDS \usepackage{ifthen} in the document preamble

\newenvironment{lpconstraintsraw}{%
\displaystyle\begin{array}{ll}
}{%
\end{array}%
}
\newenvironment{lpconstraints}{\begin{center}$\begin{lpconstraintsraw}%
}{\end{lpconstraintsraw}$\end{center}}
\newenvironment{lp}[3]{%
\begin{center}
\begin{tabular}{lrlr}
\ifthenelse{\equal{#1}{}}{}{({#1})} & {#2} & $\displaystyle{#3}$ &\\
                                    & where & $\left\{\begin{lpconstraintsraw}
}{%
\end{lpconstraintsraw}\right.$ &\\
\end{tabular}
\end{center}%
}
\newenvironment{minlp}[2]{\begin{lp}{#1}{minimize}{#2}}{\end{lp}}
\newenvironment{maxlp}[2]{\begin{lp}{#1}{maximize}{#2}}{\end{lp}}

\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}

\title{Fractional Decomposition Trees: Finding Feasible Solutions to Integer Programs with Bounded Integrality Gap}


\author{
\parbox[t]{6cm}{\centering
Robert Carr\\
\small{{Sandia National Laboratories\\{\tt rdcarr@sandia.gov}}}\\
%\footnotesize{rdcarr@sandia.gov}
}
\parbox[t]{6cm}{\centering
Cynthia Phillips\thanks{
Discrete Algorithms and Math Department, Sandia National Laboratories, Albuquerque, NM, USA.
\texttt{caphill@sandia.gov}.
Sandia is a multipurpose laboratory
operated by Sandia Corporation, a Lockheed-Martin Company, for the
United States Department of Energy under contract DE-AC04-94AL85000.
}\\
\small{{Sandia National Laboratories\\{\tt caphill@sandia.gov}}}\\
%\footnotesize{caphill@sandia.gov}
}
}% end author


\begin{document}
\special{papersize=8.5in,11in}

\maketitle

\thispagestyle{empty}
\setcounter{page}{0}

\begin{abstract}
We present a new algorithm for finding a feasible solution for a
integer program. The algorithm runs in polynomial time and is
guaranteed to find a feasible integer solution provided the
integrality gap is bounded.  The algorithm is based on convex
decomposition of scaled linear-programming relaxations, so in general
it provides a suite of integer solutions.  Because of the relationship
between convex decomposition and integrality gaps, this algorithm
could also be a tool for experimentally evaluating integrality gaps of
integer programming formulations.  We apply the decomposition
procedure to a set of hard-to-decompose instances of the traveling
salesman problem.  Our preliminary computational results offer some
support for the $4/3$ conjecture and show that the FDT algorithm can
decompose fractional solutions close to optimally in practice, at
least for this class of problems.
\end{abstract}

{\bf Keywords:} integer programming, incumbent heuristics, traveling salesman, integrality gaps, approximation algorithms, branch and bound algorithms, polyhedral combinatorics

\newpage

\section{Introduction}

Mixed-integer programming (MIP), the optimization of a linear
objective function subject to linear and integrality constraints, is a
classic NP-hard problem~\cite{GJ79}.  In fact it is NP-hard in general
to determine if there is a feasible solution to a MIP
instance\cite{GJ79}.  However, intelligent branch-and-bound-based
strategies allow commericial and open-source MIP solvers to give exact
solutions (or near-optimal with provable bounds) to many specific
instances of NP-hard combinatorial optimization problems.  Unlike many
NP-hard problems, whose proof of equivalence to SAT involves a
sequence of complicated reductions, expressing an combinatorial
optimization problem as a MIP is usually natural and direct.  In
particular, it is easy to capture (linear) side constraints that
frequently arise in practical applications.  Because of the quality of
modern MIP solvers, the expressive power of MIP, and the availability
of mathematical modeling languages and tools such as AMPL\cite{ampl},
a first choice strategy for finding an optimal solution to a
particular instance of an NP-complete problem is to formulate the
instance as a MIP and try a general-purpose MIP solver.

Though commercial and free solvers are constantly improving, there are
still real-world instances of MIPs for which these solvers do not find
any feasible solution even after days of computation.  Finding a
feasible solution early in the computation can speed branch-and-bound
search by providing a value for pruning search regions and they
provide at least some solutions if applications have a time limit or
if the users must terminate the search early.

In this paper we give a polynomial-time algorithm that is guaranteed
to find a feasible solution for a broad class of integer programming
problems.  Although we cannot provide a meaningful bound on the
approximation quality of this feasible solution, there is considerable
practical benefit for finding any feasible solution for some problems.
Our algorithm is highly parallelizable, so it can make use of excess
processors early in a run.

We consider a binary MIP, which has the following form:
\begin{minlp}{MIP} {c^Tx}
Ax\ge b&\\
x_j \in \{0,1\} & \forall j \in D \subseteq \{1, \ldots, n\}\\
\ell_j \le x_j \le u_j & \forall j \not\in D
\end{minlp}
where $A$ is an arbitrary $m \times n$ matrix, $x$ is an $n$-vector of
variables, and $D$ represents the indices of the variables that must
be binary, taking on only the value $0$ or $1$.  If $D$ is the entire
set of variables, then this is an {\em integer program}
(IP). Expressing all constraints as ``greater than'' inequalities is a
convenience; We can also handle any mix of equalities or inequalities
in the other direction.  We require that the objective function $c$ is
non-negative, that is has at least one strictly positive component,
and that $c_j = 0$ for all $j \not \in D$.  That is, the continuous
variables are helper variables that do not participate in the
objective function.

If we remove the integrality constraints and allow $0 \le x_j \le 1$
for all $j \in D$, the resulting problem is the {\em
linear-programming (LP)} relaxation of the MIP.  Linear programming
problems can be solved in polynomial time~\cite{Khachian79}.  The
feasible region, the set of vectors $x$ that satisfy all the
constraints, forms an $n$-dimensional polytope $F$.  A polytope
specifies a family of MIP problems based on the objective.  Let
MIP$(F, c)$, be the optimal value of a MIP instance for a
specific objective function $c$, and let LP$(F, c)$ be the
optimal value of its LP relaxation.  The {\em integrality gap}
$g_F$ of a family of MIP instances is the largest ratio between
the optimal integer solution and the optimal value of its LP
relaxation.  Specifically:
$$ g_F = \max_c \frac{\mbox{MIP}(F, c)}{\mbox{LP}(F, c)}.$$ We will
denote the integrality gap of a MIP family by $g$ when the polytope is
understood from context. The integrality gap $g$ is {\em bounded} if
this ratio is finite.  Specifically, the optimal LP value is never
zero unless the optimal MIP value is also zero, and whenever the LP
relaxation is feasible, the MIP problem is feasible too.

We present a polynomial-time algorithm that is guaranteed to find a
feasible solution for a MIP instance provided the integrality gap of
its family is bounded and the problem obeys the structural assumptions
on the objective function given above.  For this class of MIPs, the
feasibility question is in ${\cal P}$: just solve the LP relaxation.
So we are not claiming to solve an NP-hard problem.  However, there
are problems in this class, for example scheduling problems that
always have feasible solutions, for which the best commericial solvers
still cannot find feasible solutions.  Given only a matrix
representation, it is difficult to infer underlying combinatorial
structure (such as a variant on a scheduling problem or a routing
problem).  We give the first polynomial-time algorithm that finds
solutions to these problems given only the matrix representation.

Rhagavan and Thompson\cite{RT87} show how to use randomized rounding
to find provably good approximations for covering problems.  Covering
problems fit into the class of instances for which our algorithm is
guaranteed to work (though we do not provide the quality guarantee of
randomized rounding for this case).  There are a number of heuristics
for finding feasible, preferably high-quality, solutions to MIPs such
as the feasibility pump\cite{FGL05}.  Although these can work well in
practice, they can fail to find a feasible solution and also provide
no quality guarantee.

A number of researchers (see
~\cite{BarNoyGNS01,Naor+Schieber:shallow-trees,PhillipsUW2000,Srinivasan+Teo:STOC97},
for example) have developed provably-good approximations to
combinatorial optimization problems expressed as integer programs
using {\em convex decomposition}.  Others have used the decomposition
method to develop bicriteria (pseudo)approximation
algorithms~\cite{BurchCKMPS03} or to prove structural results about
the set of feasible solutions for a combinatorial optimization
problem~\cite{BoydCarr}.

The general decomposition method works as follows. Given an integer
program (IP), let $x^*$ be an optimal solution to the
linear-programming (LP) relaxation.  Find a set of integer solutions
$S_1, S_2, \ldots, S_k$, each feasible for the MIP.  For each $S_i$ for
$i = 1, \ldots, k$, also find a $0 \le \lambda_i \le 1$ such that
$\sum_{i=1}^k \lambda_i = 1$.  These solutions form a convex
decomposition if $\sum_{i=1}^k \lambda_i S_i \le \rho x^*$, for an
appropriate scaling factor $\rho \ge 1.$ In this case, at least one of
the solutions $S_i$ is a $\rho$-approximation to the optimal MIP value.
In fact, it is no more than a factor of $\rho$ greater than the value
of the LP relaxation.  Thus $\rho$ must be at least as large as the
integrality gap of the specific instance.  Carr and
Vempala~\cite{CarrVempala} proved that $\rho$ equal to the integrality
gap is sufficient: the integrality gap is at most $\rho$ if and only
if there exists a convex combination of integer feasible solutions
dominated by $\rho x^*$ where $x^*$ is any feasible solution to the
LP.  In fact, it is sufficient to consider only extreme points for the above
decomposition.

To date, all approximation algorithms based on convex decompositions
have been problem specific, usually involving clever exploitation of
problem structure.  In this paper, we present the {\em fractional
decomposition tree (FDT)} algorithm, which works for integer programs
with bounded integrality gap.  The FDT algorithm grows a tree similar
to the classic branch-and-bound search tree for integer programs.
Each node represents a partial solution with solutions becoming
progressively more integral at each level.  Leaves contain solutions
with integer values for all binary variables that dominate an
integer-feasible solution for the MIP.  We then transform this vector
into a feasible solution.  Unlike a branch-and-bound tree, however,
the fractional decomposition tree has only a polynomial number of
nodes at each level.  The computation requires $O(n_b^2)$
linear-programming solves where $n_b$ is the number of integer
variables that have non-zero values in the LP relaxation.

The FDT algorithm produces a convex decomposition of the fractional
input point.  The scale factor $\rho$ is not guaranteed to be equal to
the integrality gap.  However, it provides an upper bound in the
integrality gap for that instance.  So consistent positive results
that give decompositions with small values of $\rho$ provide good
experimental support for small integrality gaps for specific
formulations.

We applied the FDT algorithm to fundamental extreme points of the
traveling salesman polytope with subtour-elimination constraints.
Our preliminary computation study provides some support for the $4/3$
conjecture and shows that the FDT can decompose with scaling factors
quite close to optimal.

The remainder of the paper is organized as follows.  In
Section~\ref{sec:FDT}, we present the fractional decomposition tree
(FDT) algorithm and argue its correctness.  In section~\ref{sec:tsp},
we discuss the $4/3$ conjecture for the traveling salesman problem
(TSP) and describe a preliminary experiment applying the FDT algorithm
to difficult-to-decompose instances of TSP.  In
section~\ref{sec:future}, we discuss objective function issues in more
detail, consider faster heuristics based on FDT, and describe future
research directions.

\section{The FDT Algorithm}
\label{sec:FDT}
In this section we present the fractional decomposition tree (FDT) algorithm
and argue its correctness.  We also discuss some implementation issues.

We begin by considering the Carr/Vempala result a little more
carefully.  A vector $y$ {\em dominates} a vector $x$ if each
component of $y$ is at least as large as the corresponding component
of $x$.  We require the following definition from~\cite{CarrVempala}: the
{\em dominant} ${\cal D}(Z)$ of an $n$-dimensional polyhedron $Z$ is
the set of points $y \in {\cal R}^n$ that dominate some point $x \in
Z$.  That is
$$ {\cal D} = \{y \in {\cal R}^n | \exists x \in Z: \forall i \in \{1,
\ldots, n\} y_i \ge x_i\}.$$ Consider a problem with LP feasible
region $F$.  The convex hull of the integer points within $F$ is
another convex polytope $Z$ (the integer polytope) with integer
extreme points.  Carr and Vempala proved the following theorem:
\begin{theorem}[\cite{CarrVempala}]
The integrality gap of an LP relaxation $F$ of an integral polyhedron $Z$ in the
positive orthant is the smallest real number g such that for any
extreme point $f \in F$, $gf \in {\cal D}(Z)$.
\label{thm:CV}
\end{theorem}
In other words, if we scale the LP solution by a factor $g$ at least
as large as the integrality gap, this scaled vector will be in the
dominant of the integer polytope $Z$.  Speaking practically, that
means that point $gf$ now dominates a point $z \in Z$.  Any point in
the integer polytope is a convex combination of integer feasible
(extreme-point) solutions, so $gf$ dominates a convex combination of
feasible solutions.

Classical branch and bound for integer programming grows a tree.  The
root of the tree is the original MIP problem.  We begin by solving the
LP relaxation of the MIP to get a lower bound on the optimal MIP
value.  If optimal solution to the LP relaxation is integral where
required, we are done.  That is an optimal solution to the MIP.
Otherwise, we select a binary variable $x_i$ that should be integral,
but is strictly fractional in the LP solution.  We create two
children: one where $x_i$ is forced to be $0$ and one where $x_i$ is
forced to be $1$.  The original LP solution is not feasible in either
child, so we can apply the same procedure to the children.  We prune a
node if the LP relaxation is integral or infeasible or if the lower
bound is worse than a feasible solution we've already found (hence the
value of feasible solutions found early in the search).  The procedure
terminates when there are no more open (unpruned) nodes.  This search
requires exponential time in the worst case.

In the FDT, we grow a tree in a similar way, but the tree represents
the decomposition of a feasible solution for the MIP's LP relaxation.
Each node at level $\ell$ contains a vector $x$ with integer values
for the first $\ell$ variables.  There exists, by construction, a
solution to the LP relaxation that $x$ dominates in the first $\ell$
variables and matches on the remaining variables.  Each leaf contains
a vector $x_l$ that is integral on all integer variables and dominates
an LP solution.  We prove that if the integrality gap is bounded, each
$x_l$ also dominates a feasible solution for the MIP.  We show how to
find this integer feasible solution for each leaf.

\paragraph{Growing the FDT tree}
We grow the FDT tree as follows.  The root of the FDT contains $x^*$,
a feasible fractional solution for the LP relaxation of the MIP,
usually an optimal LP solution.  If $\rho x^*$ dominates a convex
combination of integer-feasible solutions $S^1, \ldots, S^{q}$, for
some scalar $\rho$, then for all $1 \le j \le q$, we have $S^j_i= 0$
if $x^*_i = 0$.  This follows from the definition of the
decomposition: $\rho x^* \ge \sum_j \lambda_j S^j$ where $\lambda_j
\ge 0$ and $\sum_j \lambda_j = 1$. However, it's possible $S^j_i = 0$
for all $j$ even when $x^*_i = 1$, since we only require that the
scaled $x^*$ dominate the combination.  So we will not treat
coincidental non-zero integral values ($1$) as fixed.  We branch only
on variables that are fractional in a partial solution.  The zeros
will remain fixed, but the $1$'s might become fractional and require
branching later.

Consider the set of integer variables that have non-zero values in
$x^*$: $\{x_1, x_2, \ldots, x_{n_b}\}$, ordered arbitrarily. The root
has two children.  The down child contains an LP-feasible solution
$y^{0}$ with variable $x_1 = 0$ and the up child contains an
LP-feasible solution $y^{1}$ with variable $x_1= 1$. The two solutions
are chosen such that a convex combination of $y^{0}$ and $y^{1}$ packs
into a scaled version of $x^*$ with the smallest possible scaling
factor $\rho.$ That is, we have $\lambda_{0} y^{0} + \lambda_{1} y^{1}
\le \rho_{1} x^*.$ where $0 \le \lambda_{0}, \lambda_{1} \le 1$,
$\lambda_{0} + \lambda_{1} = 1$, and $\rho_1$ is as small as possible.

We solve the following linear program to compute the $y^i$.  This LP
accepts a level parameter $\ell$ which specifies which variable to
branch on and a parent vector $x$.  At the root we use LPC$(1,x^*)$

% Someday make a labeled version of the LP macros and use labels!
\begin{maxlp}{LPC($\ell, x$)} {\lambda_0 + \lambda_1}
Az^0\ge b\lambda_0&(1)\\
Az^1\ge b\lambda_1&(2)\\
0 \le z^0 \le \lambda_0&(3)\\
0 \le z^1 \le \lambda_1&(4)\\
z^0_{\ell} = 0; z^1_{\ell} = \lambda_1&(5)\\
z^0 + z^1 \le x&(6)\\
\lambda_0, \lambda_1 \ge 0
\end{maxlp}

We set $y^0 = z^0/\lambda_0$ and $y^1 = z^1/\lambda_1$.  We prove
below that the $y^i$ have the required properties with convex
multipliers $\lambda'_0 = \frac{\lambda_0}{\lambda_0 + \lambda_1}$,
$\lambda'_1 = \frac{\lambda_1}{\lambda_0 + \lambda_1}$, and $\rho =
\frac{1}{\lambda_0 + \lambda_1}$.  A more intuitive mathematical
program to compute the scale factors directly would be nonlinear.

If $\lambda_0 = 0$, then the root has only one child $y^1$, and
similarly if $\lambda_1 = 1$, the root has only the $y^0$ child.  If
the MIP instance has only one feasible solution and the integrality gap
is bounded, the ``tree'' will be a chain leading to the single
feasible solution at the leaf.

If either of the $y_i$ are integral, it is a feasible solution for the
MIP.  If this heuristic is part of a classical branch-and-bound
search, we could report this feasible solution.  If we wish to
continue the decomposition (e.g. to study integrality gaps), then this
node never requires further decomposition; it travels to the next level
of the tree unchanged.

We now decompose the children of the root.  Any descendant of the
$y^0$ (down) child must have $x_1 = 0$ by the argument above
concerning decompositions of $0$-valued components.  However
descendants of the $1$ (up) child are {\em allowed} to have $x_1 = 1$,
but not forced to.  We consider the variable $x_2$ for each of the
level-1 nodes.  If variable $x_2$ is already integer in $y^0$, then
that node passes down to level 2 unchanged.  We use linear program
LPC$(2,y^i)$.  That is, we branch on variable 2 and pack into vector $y^i$.

There is one issue with the $y^1$ (branch up) child. The LPC linear
program does {\em not} fix variable $x_1$ (from the first branching)
to $1$ when further decomposing the $y^1$ (up) child into its children
$y^{10}$ and $y^{11}$.  This produces smaller convex multipliers,
leading to better decompositions and better approximations.  It may
also be required for correctness because, as we mentioned above, the
integer points that $y^1$ dominates in variable $x_1$ may, in fact,
have $x_1 = 0$.  LPC$(2,y^i)$ might return a fractional solution for variable
$x_1$ in one or both of these children.  If so, we reset $x_1 = 1$ for
future decompositions.  Specifically, the value $w^{10}$ and $w^{11}$
stored in the level-2 descendants of the level-1 up child have
$w^{1i}_1 = 1$ (respect the branch) and otherwise have $w^{1i}_j =
y^i_j$.

We continue decomposing the solutions, building the tree breadth first
until all nodes are integral.  For each level of the FDT, the y values
(from the LPC invocations) form a convex decomposition of the root
$x^*$, with convex multipliers equal the the product of the
multipliers on the node-to-leaf path.  Each $w$ value on level $\ell$
is integral for the first $\ell$ values, reflecting the branching
decisions to that point.  Vector $w$ dominates an LP solution that
respects the $0$ branches.

To control the size of the tree, we prune a level if it has more than
$\alpha n_b$ nodes for some constant $\alpha > 1$.  Suppose there are
$k > \alpha n_b$ nodes on some level with partial solutions $y_1, y_2, \ldots
y_k$.  We use the following linear program to prune the level:

\begin{maxlp}{LPP} {\sum_{i=1}^k\lambda_i}
\sum \lambda_i y_i \le x^*&\\
0 \le \lambda_i \le 0 & \forall i=1\ldots k
\end{maxlp}

\noindent where $x^*$ is the original LP relaxation, the solution at the root of
the FDT.  This linear program ``repacks'' all the partial solution and
recomputes a new $\rho = 1/\sum_i \lambda_i.$ We only need to enforce
the packing on the nonzero variables, since binary variables that were
zero in $x^*$ will be zero in all decompositions.  So there are $n_b$
constraints.  Therefore, there can be at most $n_b$ values of
$\lambda_i$ that are basic.  All others will be $0$.  We keep the
solutions corresponding to the nonzero values of $\lambda_i$.  Thus no
level of the FDT has more than $n_b$ nodes.  After expanding all nodes
to leaves, we can run the pruning LP a final time to compute a final
packing with minimum $\rho.$

\paragraph{Finding feasible solutions from the FDT}
Each leaf in the FDT contains a vector $x_l$ that has integer values
for all binary variables.  It dominates an LP solution, but it may not
be LP feasible.  We reduce some of the $1$-valued variables in $x_l$
to produce an integer-feasible solution.  Since the objective function
is non-negative, this also improves the cost of the solution.

Suppose we have a vector $x \in {\cal D}(Z)$ for some integer polytope
$Z$ ($x$ is in the dominant of $Z$), and suppose that $Z$ has an
integer point.  We fix each variable iteratively, starting with $x_1$.
Suppose we have fixed $k \ge 0$ variables so far, yielding a partial
solution $x^{(k)}$.  We run the following linear program
(dominant-to-feasible), parameterized by $k$, to determine the value for $x_{k+1}$:
\begin{minlp}{LPD2F(k)} {y_{k+1}}
Ay\ge b&\\
y_j = x^{(k)}_j & \forall j \le k\\
y_j \le x^{(k)}_j & \forall j \ge k+1\\
y \ge 0
\end{minlp}

This LP finds the minimum value of the $k+1$st component for a solution that
is LP feasible, dominated by $x$, and respects the component decisions we have
made so far.

The procedure DOM2IP, shown in figure~\ref{fig:D2I} uses this LP to
compute a feasible integer solution from a point in the dominant.

\begin{figure}[tbh]
{\footnotesize
\begin{center}
\begin{boxedminipage}{3.2in}
\begin{alltt}
Input: \( x\sb{l} \) from FDT leaf
    \( x\sp{(0)} = x\sb{l} \)
    \( \mbox{for} k := 0 \mbox{to} n\sb{f}-1\)
       let \( x\sp{(k+1)} = x\sp{(k)} \)
       let a = solution to LPD2F(k)
       if a = 0 then \( x\sp{(k+1)}\sb{k+1} = 0 \)
       else \( x\sp{(k+1)}\sb{k+1} = 1 \)
\end{alltt}
\end{boxedminipage}
\end{center}
\caption{The algorithm to convert a vector in the dominant of the integer polytope
into an integer feasible solution.  LPD2F(k) is a linear program that computes the minimum
possible value for the (k+1)st component. \label{fig:D2I}.}
}
\end{figure}

\paragraph{Correctness}
We now show that the FDT algorithm is correct.  First we show that
using the linear program LPC, we correctly decompose the vector $x$ in
a level-$\ell$ FDT node into two child problems $y^0$ and $y^1$ that
respect the $0$ values in vector $x$, enforce the branching on the $\ell$th variable, and pack
into $x$.  Recall we set $y^0 = z^0/\lambda_0$ and $y^1 =
z^1/\lambda_1$, where the $z^i$ are the vectors computed by
LPC$(\ell,x)$.  We require $\lambda_{0} y^{0} + \lambda_{1} y^{1} \le
\rho_{1} x.$ We now show that the vectors $y^i$ have the required
properties with convex multipliers $\lambda'_0 =
\frac{\lambda_0}{\lambda_0 + \lambda_1}$, $\lambda'_1 =
\frac{\lambda_1}{\lambda_0 + \lambda_1}$, and $\rho =
\frac{1}{\lambda_0 + \lambda_1}$.

Because $z^0 = \lambda_0y^0$, Constraints (1) imply that $A(\lambda_0y^0) \ge \lambda_0b$,
or that $Ay^0 \ge b$.  Thus $y^0$ is LP feasible.  Similarly from constraints (2) and the
definition of $y^1$ imply that $y^1$ is LP feasible.  Constraints (3) and (4) imply that
the elements of vectors $y^0$ and $y^1$ are bounded between $0$ and $1$.  Constraints
(5) enforce the branching by setting the value of the $\ell$th variable to appropriate integer
values.  Constraint (6) enforces the decomposition:
\begin{eqnarray*}
z^0 + z^1 & \le & x^*\\
\lambda_0\left(\frac{z^0}{\lambda_0}\right) + \lambda_1\left(\frac{z^1}{\lambda_1}\right) & \le & x^*\\
\lambda_0y^0 + \lambda_1y^1 & \le & x^*\\
\left(\frac{\lambda_0}{\lambda_0 + \lambda_1}\right)y^0 + \left(\frac{\lambda_1}{\lambda_0 + \lambda_1}\right)y^1 & \le & 
       \left(\frac{1}{\lambda_0 + \lambda_1}\right)x^*\\
\lambda'_0 y^0 + \lambda'_1 y^1 & \le & \rho x^*.
\end{eqnarray*}
We have $\lambda'_0 + \lambda'_1 = \frac{\lambda_0}{\lambda_0 + \lambda_1} + \frac{\lambda_1}{\lambda_0 + \lambda_1} = 1$,
and both are nonnegative.

Because LPC is correct, by construction each leaf $l$ contains a
vector $x_l$ that is integral and dominates an LP solution.  We now
prove the correctness of algorithm DOM2IP that converts a vector in
the dominant into a feasible solution for the MIP.  Specifically, we
need to prove that $x_l$ dominates an {\em integer} feasible solution
and that DOM2IP correctly finds such a solution.

We require the following notation.  Let $F$ be the feasible region for the
LP relaxation of the MIP.  Let $K$ be the depth of the FDT tree.  And let
$x^{(k)}$ be the solution after $k$ iterations of the inner loop of algorithm
DOM2IP in figure~\ref{fig:D2I}. For $k=0,1,\ldots, K$, we define:
\begin{displaymath}
\begin{array}{llllll}
LP^{(k)} &:=& \{y \in F & | & y\leq x^{(k)}\mbox{ and 1st $k$ positions 
fixed by DOM2IP}\} \\
IP^{(k)} &:=& \{y\in LP^{(k)} & | & y\in \{0,1\}\mbox{ on binary variables}\}.
\end{array}
\end{displaymath}

The following theorem proves that the DOM2IP procedure preserve integer feasibility
through each iteration:

\begin{theorem}
Let MIP be a binary MIP with integrality gap $g$ and costs only on the
binary variables. Let $x^*$ be a point that is 0-1 on the binary
variables MIP and dominates a solution of an LP relaxation of MIP.
Without loss of generality, let the first $K>0$ values of $x^*$ be
integer variables that are at $1$ and the rest integer variables at
$0$ or continuous variables.  Let $x^{(0)},x^{(1)},\ldots,x^{(K)}$ be
the sequence of increasingly-integral solutions from algorithm DOM2IP
and $IP^{(0)},IP^{(1)},\ldots, IP^{(K)}$ be the MIP problem constrained
to respect these decisions.  Then,
$$\forall k\in \{0,\ldots,K\}\quad IP^{(k)}\neq \emptyset.$$
\end{theorem}
{\bf Proof: } In this proof, when we make statements about dominance
or state inequalities between vectors, we ignore continuous variables.
We prove this by induction on $k$.  We start with $x^{(0)}:=x_l$ which
dominates a solution of the LP relaxation when $x_l$ is a leaf
obtained from the FDT algorithm or otherwise satisfies the conditions
of this theorem.

For $k=0$, we have $LP^{0}\neq \emptyset$ and a finite integrality gap
$g$ for the LP relaxation.  Thus, by Theorem~\ref{thm:CV}, $IP^{0}\neq
\emptyset$.

Assume the theorem holds for all values up to an arbitrary $k<K$.
The problem LPD2F(k) can be interpreted as the following LP:
\begin{displaymath}
\begin{array}{llllll}
\mbox{minimize}& y_{k+1} \\
\mbox{subject to}& y\in LP^{(k)}.
\end{array}
\end{displaymath}
This LP has a feasible solution because $IP^{(k)} \neq 0$, by the induction
hypothesis and any solution to $IP^{(k)}$ satisfies the constraints of the LP.

Suppose first that the minimizer $y^*$ achieves $y^*_{k+1}=0$.  Then 
DOM2IP fixes $x^{(k+1)}_{k+1}$ to $0$ and we have $y^*\in LP^{(k+1)}$.  
Since $y^*\leq x^{(k+1)}$, $y^*\in F$, and the integrality gap of the MIP is finite, 
by Theorem~\ref{thm:CV},  we have
$$S_{k+1}:=\{y\in IPfeas\, |\, y\leq x^{(k+1)}\}\neq \emptyset,$$ 
where $IPfeas$ is the set of integer feasible solutions.  
Let $\hat{y}\in S_{k+1}$.  We show by contradiction that $\hat{y}\in 
IP^{(k+1)}$.  Suppose  $\hat{y}\not \in IP^{(k+1)}$.  Then there is a 
smallest $1\leq l\leq k$ such that $\hat{y}_l=0$ but $x^{(k+1)}_l=1$.  
But then $\hat{y}\leq x^{(k+1)}\leq x^{(l-1)}$.  The latter inequality
follows from the nature of DOM2IP.  Because it only sets $1$ values to $0$,
the vector produced at each iteration is dominated by the vector from the
previous iteration.  Furthermore, we have $\hat{y}\in F$, and 
$\hat{y}$ respects how variables $1,\ldots,l-1$ are fixed by DOM2IP.  
Thus, $\hat{y}\in LP^{(l-1)}$.  But, $\hat{y}_l=0$ contradicting the 
fact that the minimum to the linear program that fixed variable $l$ was 
greater than $0$.  Thus, $IP^{(k+1)}\neq \emptyset$ in this case.  

Now suppose that the minimizer $y^*$ has $y^*_{k+1}>0$.  Then $x^{(k+1)}_
{k+1}$ is fixed to $1$.  Now, $\forall z\in IP^{(k)}\quad z\in LP^{(k)}$ 
and hence $z_{k+1}>0$, and therefore $z_{k+1}=1$.  So, $z \in LP^{(k+1)}$ 
and $z$ is integer.  Thus, $z\in IP^{(k+1)}$, showing  
$IP^{(k+1)}\neq \emptyset$ in this case too.  \hfill \framebox  

\begin{corollary}
Running the DOM2IP algorithm starting from a leaf of the FDT tree will produce
a feasible solution for any MIP with finite integrality gap.
\end{corollary}

By straight averaging, one of the solutions we compute will have an
approximation ratio of at most $\rho$, where $\rho$ is the value
returned after the final packing.  The final $\rho$ value (expansion
factor) will not generally be equal to the integrality gap $\rho_g$ of
the instance.  Each individual LCP instance will have $\rho \le
\rho_g$.  This is because each LCP instance is decomposing a solution
that dominates an LP-feasible solution by construction.  Therefore a
decomposition exists with expansion factor at most $\rho_g$.  At level
$i$, the appropriate convex combination of integer feasible solutions
with appropriate values for the first $i-1$ levels and with $i$th
variable equal to $0$ is a feasible value of $y^0$. Similarly the
convex combination of integer feasible solutions with $i$ variable
equal to $1$ is feasible for $y^1$.  However, the error can compound
at each level.  In the worst case, one could imagine a final scaling
value of $\rho_g^{n_b}$.  The pruning LPs (LPP) reduce the value of
$\rho$ and in practice do not expect this worst-case growth in $\rho$.
If $\rho_g$ is bounded, then even this worst case bound is finite and
the FDT will find an integer feasible solution.

\section{Preliminary Computational Experience with the TSP}
\label{sec:tsp}

The traveling salesman problem (TSP) is one of the most studied
combinatorial optimization problems, both in terms of approximation
algorithms and heuristics and its polyhedral structure.  Given a
complete undirected graph with edge weights satisfying the triangle
inequality, we wish to find a tour of minimum total edge length that
visits each node in the graph.

If an IP formulation for TSP only enforces that each node have degree
at least 2, the integer solutions might have multiple disjoint
subtours that together cover all the nodes.  The {\em
subtour-elimination constraints} require that for each subset $S$ of
the nodes, there are at least two edges between $S$ and $\bar{S}$.
There are an exponential number of such constraints, but one can
enforce them via separation using a minimum cut algorithm.  For our
example, we enforce the subtour elimination constraints using Carr
et.\ al.'s compact representation\cite{CarrKLNP07}.

Shmoys and Williamson~\cite{ShmoysWilliamson} has used the
Christofides upper bound~\cite{Christofides76} to prove that the
integrality gap of a TSP formulation with the subtour-elimination
constraints is at most $3/2$.  There is an example showing the
integrality gap is at least $4/3$. Wolsey and later Goemans
conjectured that the actual gap is $4/3$.  This is {\em $4/3$
conjecture}.  Boyd and Labont\'{e}~\cite{BoydLabonte} experimentally
proved this conjecture for problems with up to $10$ vertices.  Boyd
and Carr~\cite{BoydCarr} conjectured that for all extreme points $x^*$
of an IP formulation with the subtour constraints $\frac{4}{3}x^* \ge
\sum_i \lambda_i x^i,$ where the $\lambda_i$ form a convex
decomposition and the $x^i$ are {\em Eulerian} graphs.  That means the
$x^i$ are subgraphs of the complete graph with edge weights in
$\{0,1,2\}$ such that the sum of the weights of the edges adjacent to
any node is even.  Boyd and Carr~\cite{BoydCarr} together with Carr
and Vempala~\cite{CarrVempala} proved this statement is equivalent to
the $4/3$ conjecture.

Boyd, Carr, and Ravi~\cite{BoydCarr,CarrRavi} proved that if the $4/3$
conjecture holds for {\em fundamental extreme points}, then it holds
for all extreme points.  A fundamental extreme point $x^*$ has
non-zero values on edge variables with the following structure,
illustrated in Figure~\ref{fig:fundExtreme}.  There are an even number
of nodes.  All nodes on a single cycle.  Values in $x^*$ for edges on
the cycle alternate between $0 \le \sigma \le 1$ and $0 \le 1 - \sigma
\le 1$.  Each node also has precisely one chord across the cycle with
$x^*$ value equal to $1$.  Technically there are arbitrarily-many
degree-$2$ vertices on each chord.  This is necessary to force
worst-case behavior.  We need not explicitly model these vertices.  We
simply note that in any decomposition, the values for variables that
represent chord edges must be either $1$ or $2$.

\begin{figure}
\begin{center}
\input{fundExtreme.latex}
\end{center}
\caption{A fundamental extreme point with 8 nodes along the cycle.}
\label{fig:fundExtreme}
\end{figure}

We customized the FDT algorithm for this TSP problem.  Specifically,
we considered the class of general integer variables with only the
values $1$ and $2$.  The tree is still binary, but we must branch on
all of these general integer variables even if they are exactly equal
to $1$ in the fractional solution $x^*$.  We implemented this in the
ampl running on a linux workstation with 2 3.2Ghz Pentium 4 processors
and 512Kb of cache.  We used the PICO solver as the back end to ampl,
calling the CLP linear programming solver from PICO.

We generated 3600 instances of fundamental extreme points with 20
vertices on the cycle.  This is a small instance, but is still
relevant for the study of the $4/3$ conjecture because it represents
significantly larger TSP graphs.  We generated chords greedily at
random, throwing out instances that did not have the appropriate chord
structure (e.g. when the last edge was an edge on the cycle).  This
does not uniformly sample from among all fundamental extreme points.
One can use a minimum cut algorithm to compute the optimal value for
$\sigma$, and to throw out instances that are infeasible because the
global (fractional) minimum cut is less than 2.  However, for this
preliminary study, we simply set $\sigma = 0.5$.  This adds a degree
of freedom compared to using true extreme points and therefore may
make the decomposition somewhat easier.  With no optimization, other
than using the strong compact formulation, the instances solved in
about 11 seconds.

Of the 3600 instances, 56 were invalid TSP relaxations.  Of the
remaining 3544 instances, 2032 or 57\% had a final $\rho \le 4/3$.  Of
these $929$ were exactly $4/3$ and remaining 1103 were superoptimal
packings with respect to the true integrality gap for the problem
family.  For example, this will happen if the FDT algorithm finds an
optimal solution to the TSP problem.  Of the 3544 valid instances, 178
or 5\% had $4/3 < \rho \le 3/2$.  Finally, 1334 or 38\% had $\rho >
3/2$.  In this case, the final packing scaling factor was larger than
an upper bound on the true integrality gap.  However, the worst-case
instance had $\rho = 2$.  Thus although the theoretical bound on FDT's
performance for this case was approximately $(4/3)^{30}$, it actually
performed at or near optimal in all cases.

\section{Discussion}
\label{sec:future}

TODO: We can get a feasible solution for a problem with bounded integrality gap by
just applying the DOM2IP algorithm.  But starting with solutions from the FDT leaves
will be better in general.

In this section we consider variations on the algorithm, heuristic versions that
may be faster (but may fail to find a feasible solution), implementation issues,
and future directions.

Though it is easier conceptually to have each level of the FDT correspond to a
single variable, the algorithm also works if at each level, nodes branch on
any fractional variable.  Because unfixed $1$-valued variables can become fractional,
one must generally make multiple passes over the variables before the decomposed solutions
become integral.  All nodes at each level have the same number of branches, and therefore
we make progress at each level.

We can extend the method to general integer variables, provided the number
of values for each general integer variable is finite.  Instead of creating
two children, we create $c$ children when branching on an integer variable
with $c$ possible values.  For most reasonable IP models, $c$ will be a small
constant for all general integer variables.

This algorithm works for MIPs that have continuous variables contributing to the
objective function when these variables are always binary at extreme points of the
integer polytope.  For example, for the p-median integer program~\cite{MF90}, there are binary
decision variables representing the location of facilities and continuous (implied
binary) variables representing facility assignments to customers.  Only the
continuous (effectively binary) variables contribute to the objective function.

If one considers families of MIPs, such as the p-median problem, where some binary
variables never contribute to the objective function, then the quality of the LPC
decompositions depends only upon the integrality gap $g$ that comes from considering
only objective functions that are always $0$ on these non-contributing variables.
We require that the complementary gap $g'$, where the objective function is non-zero
only on non-contributing variables is finite.  Regardless of how large $g'$ is, it
has no effect on the performance of LPC.

If we force the upward branches in the LPC linear program, then we can use the
results of that LP directly in the FDT nodes.  These vectors are always LP feasible
and we need not go through the DOM2IP computation to move a leaf to the LP feasible
region.  This worked quite well for the TSP example we describe here.  However, we
cannot yet prove that this variant will always give a feasible solution.  It's possible
we may prune away all integer solutions.

If one would like a single feasible solution as quickly as possible,
one can dive on a single path in the FDT.  Heuristically, one can
initially travel down the child with highest value of $\lambda _i$, or
one can chose randomly based on the values of $\lambda _i$.  This dive is
not guaranteed to find a feasible solution.  However, particularly in
a parallel computing environment, this might find a feasible solution
much faster ($O(n_b)$ LP solves) than the time required to run the whole FDT algorithm.

We need not actually grow a tree, maintaing parent/child links,
though there may be some value to that if we are doing multiple dives.
When computing a full decomposition, we can keep the tree nodes in a
queue, stored with their level.  We take the first node in the queue,
expand it, and put the children back at the end of the queue if
appropriate.  We can detect a change in levels when the node leaving
the queue has a higher level.  At that point, we can alter the working
LPC, putting in the new bounds for constraints (5).  Otherwise, we
need only alter the righthand side of constraints (6).  We report any
integer solutions as possible incumbents, but keep them for the
pruning phase.

\iffalse
The PICO integer programming solver computes gradients (LP bound
movement per unit variable up or down change) for all integer
variables with fractional values in $x^*$.  In practice, it may be
good to order the fractional variables by gradient.
\fi

Given the speed of unoptimized versions of this problem run in ampl,
we expect more carefully crafted C++ versions run from within PICO
will allow us to investigate significantly larger TSP instances.
Computing the optimal $\sigma$ values is also an obvious way to make
the TSP results more compelling.  We are investigating ways to generate
fundamental extreme points uniformly at random.  We can also consider
ultra fundamental extreme points~\cite{CarrVempala}, which are even
harder to decompose than fundamental extreme points.

Given the computational cost of running FDT, we expect general MIP
solvers will use it only on classes of problems for which faster
heuristics consistently fail.  However, for applications that require
a feasible solution, the FDT algorithm guarantees a polynomial-time
solution for the broadest class of MIPs to date.

\paragraph{Acknowledgements}  The authors are grateful to Jonathan Eckstein and Jeff
Linderoth for helpful discussions.  We thank David Gay for his help with ampl runs.
\bibliographystyle{plain}
\bibliography{FDT}

\end{document}
